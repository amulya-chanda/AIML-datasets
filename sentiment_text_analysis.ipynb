{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2505fa58-250b-4f99-ae80-ac4c82b48825",
   "metadata": {},
   "source": [
    "These are the preprocessing steps I'm doing for this dataset\n",
    "1. to check whether dataset contains nulls, in this there are no null values\n",
    "2. dataset is balanced or not, I'm having balanced dataset\n",
    "3. Dropping unwanted columns, In this dataset 'ids','date','flag','user' are not depending on output column so I'm dropping those columns\n",
    "4. To check whether we are having duplicates If so we are dropping duplicate rows in this dataset\n",
    "5. preprocessing the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a4612a1-d8e8-4873-93a6-5bd1560eb38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/amulya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/amulya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/amulya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    800000\n",
      "4    800000\n",
      "Name: count, dtype: int64\n",
      "flag\n",
      "NO_QUERY    1600000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import contractions\n",
    "from num2words import num2words\n",
    "from textblob import TextBlob\n",
    "from spellchecker import SpellChecker\n",
    "import re\n",
    "from decimal import Decimal\n",
    "import plotly.express as px\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "column_names = ['target','ids','date','flag','user','text']\n",
    "\n",
    "df = pd.read_csv('/users/amulya/Downloads/sentiment_text_analysis.csv',encoding='ISO-8859-1', header=None, names=column_names)\n",
    "df.head(2)\n",
    "nulls = df.isnull().sum()\n",
    "# print(nulls)\n",
    "print(df['target'].value_counts())\n",
    "print(df['flag'].value_counts())\n",
    "\n",
    "# df['target'] = df['target'].replace({4:1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "effaaf1f-0142-42e2-b6c7-62b7031388dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted_columns = ['ids','date','flag','user']\n",
    "df = df.drop(unwanted_columns,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80b5cd9b-1703-405c-ab23-fdff49ff8ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    800000\n",
      "4    800000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5816bc2-ac39-436f-b2c5-57d61123542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "size, dups = df.size, df.duplicated().sum()\n",
    "# pie = px.pie(values=[size, dups], names=[\"Total Size\", \"Duplicates\"], hole=0.4, title=\"Duplicates vs Total Size\")\n",
    "# pie.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f866f1bc-574d-49f8-b580-3edd785f3e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "\n",
    "# Get size and count of duplicates\n",
    "size = df.size\n",
    "dups = df.duplicated().sum()\n",
    "\n",
    "# Pie plot\n",
    "# pie = px.pie(values=[size, dups], names=[\"Total Size\", \"Duplicates\"], hole=0.4, title=\"Duplicates vs Total Size\")\n",
    "# pie.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c0f507a-f6db-4a03-aee7-d639c95098f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "4    793506\n",
      "0    790185\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dae6563-67b8-4d22-97da-5548ba01201d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1583691 entries, 0 to 1599999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   target  1583691 non-null  int64 \n",
      " 1   text    1583691 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 36.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a0310b2-9b77-41f3-8ca7-6427b3d39948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower() # to convert all the text to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dac9902-1acd-40e1-92ff-14ee341149c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['text'] = df['text'].apply(lambda x:re.sub('[\\d]','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f19f3ef3-eacd-4bf7-a4e4-ea46de9d8f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(lambda s: ' '.join(re.sub(\"(w+://S+)\", \" \", s).split()))  # to remove links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3af371ee-e7c5-4ba1-a267-a41967c05a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(word_tokenize) # Tokenization (splitting a sentence in to tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6ce08ac-6815-4ad8-ac6e-c5cb412dec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# punctuation = set(string.punctuation)\n",
    "# df['text'] = df['text'].apply(lambda tokens: [token for token in tokens if token not in punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07027c1f-bf19-4ff2-b407-c1e9942e62b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = set(stopwords.words('english'))\n",
    "# df['text'] = df['text'].apply(lambda tokens: [token for token in tokens if token not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deffd1f2-fd21-4bfd-9d73-334f3846b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "df['text'] = df['text'].apply(lambda tokens: [lemmatizer.lemmatize(token) for token in tokens]) #Applying lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88ca748a-3b51-492b-8fd1-eacaf670e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda tokens: [contractions.fix(token) for token in tokens]) # (don't -> do not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22688d38-a473-403b-8009-26af1dcd1593",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda tokens: [token for token in tokens if token.isalnum()]) # removing special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b19ecf85-ec0d-491b-b500-9bc38641e1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda tokens: [token.strip() for token in tokens]) # removing extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d07c992-9eb2-448f-ae23-c46d4090d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['text'] = df['text'].apply(lambda tokens: [num2words(token) if isinstance(token, int) else token if isinstance(token, Decimal) else token for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3b87898-744f-4b28-a61c-c46c95ff80f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda tokens: ' '.join(tokens)) # combining all these to single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3fc61ff-c6d5-4eb9-9b8e-681e74d20d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    switchfoot http awww that a bummer you shoulda...\n",
       "1    is upset that he ca update his facebook by tex...\n",
       "2    kenichan i dived many time for the ball manage...\n",
       "3         my whole body feel itchy and like it on fire\n",
       "4    nationwideclass no it not behaving at all i ma...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f8406c-d3c5-4a59-8475-deb367ccfe2c",
   "metadata": {},
   "source": [
    "Below I'm inporting keras from tensorflow\n",
    "1. I'm having large size of dataset so I'm taking 200000 sample of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa8f2cb7-533f-4ef1-98d4-8e1c49c5ce88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790185\n",
      "793506\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   target  200000 non-null  int64 \n",
      " 1   text    200000 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense, LSTM, SpatialDropout1D, Conv1D, Bidirectional, LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "\n",
    "class_0 = df[df['target'] == 0]\n",
    "class_1 = df[df['target'] == 4]\n",
    "print(len(class_0))\n",
    "print(len(class_1))\n",
    "sampled_class_0 = class_0.sample(n=100000, random_state=42)\n",
    "sampled_class_1 = class_1.sample(n=100000, random_state=42)\n",
    "new_df = pd.concat([sampled_class_0, sampled_class_1])\n",
    "new_df = new_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "new_df.info()\n",
    "text = new_df['text'].tolist()\n",
    "target = new_df['target'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4981b2-d198-4acf-8f90-0ee88cedc51f",
   "metadata": {},
   "source": [
    "Below I'm replacing output column classes with 1 for positive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86864e9a-c708-4b13-acb7-a10f19b14c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    100000\n",
       "0    100000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['target'].value_counts()\n",
    "new_df['target'] = new_df['target'].replace({4:1})\n",
    "new_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37befc9f-7905-4ed4-9488-5a11e190727d",
   "metadata": {},
   "source": [
    "Below I'm coverting text to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b63374d-f519-4ea6-8dc3-d159c9e5ecc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "Maximum sequence length: 20\n",
      "Average sequence length: 20.0\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "vocab_size = 30 # creates embeddings lessthan 30\n",
    "encoded_reviews = [one_hot(d, vocab_size) for d in new_df['text']]\n",
    "# print(encoded_reviews)\n",
    "padded_reviews = pad_sequences(encoded_reviews, maxlen=20, padding='post') # maxlen - 20 : no. of columns\n",
    "print(len(padded_reviews))\n",
    "sequence_lengths = [len(seq) for seq in padded_reviews]\n",
    "print(f'Maximum sequence length: {max(sequence_lengths)}')\n",
    "print(f'Average sequence length: {np.mean(sequence_lengths)}')\n",
    "\n",
    "\n",
    "max_len = int(np.percentile(sequence_lengths, 95))\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5624f99-915a-418e-95c9-ced731bee1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(padded_reviews, new_df['target'], test_size=0.2, random_state=42) # splitting the data in to train and validation data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaea032-3fc4-4034-bb91-fe59d9a1dd2b",
   "metadata": {},
   "source": [
    "Below I'm building neural network by applying embedding layer and other layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6690da91-6d64-49ef-a6c4-9053601e9b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/amulya_base/lib/python3.9/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN, Dropout\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.initializers import GlorotUniform, he_uniform\n",
    "\n",
    "embeded_vector_size = 20 # no. of neurons \n",
    "model = Sequential()\n",
    "initializer = he_uniform()\n",
    "initializer1 = GlorotUniform()\n",
    "# model.add(Embedding(vocab_size, embeded_vector_size, input_length=20, name=\"embedding\"))\n",
    "model.add(Embedding(vocab_size, embeded_vector_size, input_length=20))\n",
    "# model.add(SimpleRNN(256, return_sequences=True, name=\"simple_rnn\"))  # Simple RNN layer\n",
    "# model.add(LSTM(512, name=\"lstm\"))\n",
    "# model.add(Dense(512,kernel_initializer = initializer, activation='relu'))\n",
    "# model.add(Dense(512,kernel_initializer = initializer, activation='relu'))\n",
    "# model.add(Dense(512,kernel_initializer = initializer, activation='relu'))\n",
    "# # model.add(Dense(512,kernel_initializer = initializer1, activation='tanh'))\n",
    "# model.add(Dense(512,kernel_initializer = initializer, activation='relu'))\n",
    "# model.add(Dense(512,kernel_initializer = initializer, activation='relu'))\n",
    "# model.add(Dense(512,kernel_initializer = initializer, activation='relu'))\n",
    "# model.add(Dense(512,kernel_initializer = initializer, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "581c8095-fee4-4f0b-ad06-8df3f0bfc1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef13e04d-81b7-4297-b932-e45652ff4aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m)         │           \u001b[38;5;34m600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m6,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m66,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m66,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">402,329</span> (1.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m402,329\u001b[0m (1.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">402,329</span> (1.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m402,329\u001b[0m (1.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b39cee5a-91a0-498b-bd10-3d0b3910b55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6, 20, 19, ..., 24, 14,  1],\n",
       "       [ 5, 11,  4, ...,  0,  0,  0],\n",
       "       [10, 26, 28, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [16, 17,  6, ...,  0,  0,  0],\n",
       "       [ 2, 29, 18, ...,  2, 18, 18],\n",
       "       [ 4,  7, 11, ...,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35177107-1418-496f-8af2-7c34ec6c5b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 10ms/step - accuracy: 0.5607 - loss: 0.6818 - val_accuracy: 0.5922 - val_loss: 0.6676\n",
      "Epoch 2/4\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 10ms/step - accuracy: 0.5872 - loss: 0.6695 - val_accuracy: 0.6007 - val_loss: 0.6596\n",
      "Epoch 3/4\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 10ms/step - accuracy: 0.5978 - loss: 0.6633 - val_accuracy: 0.6064 - val_loss: 0.6560\n",
      "Epoch 4/4\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 10ms/step - accuracy: 0.6018 - loss: 0.6600 - val_accuracy: 0.6112 - val_loss: 0.6505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3316f8550>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_reviews, new_df['target'], epochs=4, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11be04a8-fbcd-4e5a-bbe3-0b565bbd3e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
